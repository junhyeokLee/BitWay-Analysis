"""
requirements.txt ì— ë“¤ì–´ê°ˆ íŒ¨í‚¤ì§€
---------------------------------
requests
pandas
numpy
firebase-admin
python-dotenv
"""

import requests
import pandas as pd
import numpy as np
import firebase_admin
from firebase_admin import credentials, firestore
from datetime import datetime
import os  # OpenAI í‚¤ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
from dotenv import load_dotenv
load_dotenv()
import time
import random

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) Firestore ì´ˆê¸°í™” â”€ ì„œë¹„ìŠ¤ ê³„ì • JSON ê²½ë¡œ ìˆ˜ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cred = credentials.Certificate("firebase_key.json")
firebase_admin.initialize_app(cred)
db = firestore.client()

UPBIT_HEADERS = {"Accept": "application/json"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ì—…ë¹„íŠ¸ ì¼ë´‰ ìº”ë“¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_upbit_daily_candles(market="KRW-BTC", count=30):
    url = "https://api.upbit.com/v1/candles/days"
    params = {"market": market, "count": count}
    response = requests.get(url, params=params, headers=UPBIT_HEADERS, timeout=5)
    response.raise_for_status()
    data = response.json()

    df = pd.DataFrame(data)
    df = df.rename(columns={
        "candle_date_time_kst": "date",
        "opening_price": "open",
        "high_price": "high",
        "low_price": "low",
        "trade_price": "close",
        "candle_acc_trade_volume": "volume"
    })
    df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")
    return df.sort_values("date").reset_index(drop=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ê¸°ìˆ  ì§€í‘œ ê³„ì‚°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calculate_rsi(prices, period=14):
    delta = prices.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(period).mean()
    avg_loss = loss.rolling(period).mean()
    rs = avg_gain / (avg_loss + 1e-8)
    rsi = 100 - (100 / (1 + rs))
    return round(rsi.iloc[-1], 2)

def calculate_macd(prices, short=12, long=26, signal=9):
    short_ema = prices.ewm(span=short, adjust=False).mean()
    long_ema  = prices.ewm(span=long,  adjust=False).mean()
    macd = short_ema - long_ema
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    return round(macd.iloc[-1], 5), round(signal_line.iloc[-1], 5)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ê³ ê¸‰ ì°¨íŠ¸ íŒ¨í„´ ê°ì§€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_pattern_enhanced(highs, lows):
    recent_highs = highs[-20:].to_numpy()
    recent_lows  = lows[-20:].to_numpy()

    def is_ascending_triangle():
        highs_diff = np.diff(recent_highs[-10:])
        lows_trend = all(x < y for x, y in zip(recent_lows[-10:], recent_lows[-9:]))
        highs_flat = np.std(recent_highs[-10:]) < 0.01 * np.mean(recent_highs[-10:])
        return lows_trend and highs_flat

    def is_descending_triangle():
        highs_trend = all(x > y for x, y in zip(recent_highs[-10:], recent_highs[-9:]))
        lows_flat   = np.std(recent_lows[-10:]) < 0.01 * np.mean(recent_lows[-10:])
        return highs_trend and lows_flat

    def is_rectangle_range():
        high_range = max(recent_highs[-10:]) - min(recent_highs[-10:])
        low_range  = max(recent_lows[-10:])  - min(recent_lows[-10:])
        return (high_range / np.mean(recent_highs[-10:]) < 0.02 and
                low_range  / np.mean(recent_lows[-10:])  < 0.02)

    def is_cup_and_handle():
        if len(recent_lows) < 20:
            return False
        cup     = recent_lows[-20:-10]
        handle  = recent_lows[-10:]
        cup_bottom = min(cup)
        cup_top    = max(cup[0], cup[-1])
        handle_max = max(handle)
        return (cup[0] > cup_bottom and cup[-1] > cup_bottom and handle_max < cup_top)

    def is_falling_wedge():
        high_trend = all(x > y for x, y in zip(recent_highs[-10:], recent_highs[-9:]))
        low_trend  = all(x > y for x, y in zip(recent_lows[-10:],  recent_lows[-9:]))
        width_start = recent_highs[-10] - recent_lows[-10]
        width_end   = recent_highs[-1]  - recent_lows[-1]
        return high_trend and low_trend and width_end < width_start * 0.7

    def is_rising_wedge():
        high_trend = all(x < y for x, y in zip(recent_highs[-10:], recent_highs[-9:]))
        low_trend  = all(x < y for x, y in zip(recent_lows[-10:],  recent_lows[-9:]))
        width_start = recent_highs[-10] - recent_lows[-10]
        width_end   = recent_highs[-1]  - recent_lows[-1]
        return high_trend and low_trend and width_end < width_start * 0.7

    def is_symmetrical_triangle():
        high_trend = all(x > y for x, y in zip(recent_highs[-10:], recent_highs[-9:]))
        low_trend  = all(x < y for x, y in zip(recent_lows[-10:],  recent_lows[-9:]))
        return high_trend and low_trend

    def is_double_top():
        peaks = sorted(recent_highs[-5:])
        return abs(peaks[-1] - peaks[-2]) / peaks[-1] < 0.01

    def is_double_bottom():
        troughs = sorted(recent_lows[-5:])
        return abs(troughs[0] - troughs[1]) / troughs[1] < 0.01

    def is_head_and_shoulders():
        if len(recent_highs) < 7:
            return False
        left  = recent_highs[-7]
        head  = recent_highs[-5]
        right = recent_highs[-3]
        return (head > left and head > right and
                abs(left - right) / head < 0.1)

    def is_triple_top():
        tops = recent_highs[-6::2]
        return len(tops) == 3 and max(tops) - min(tops) < 0.01 * max(tops)

    def is_triple_bottom():
        bottoms = recent_lows[-6::2]
        return len(bottoms) == 3 and max(bottoms) - min(bottoms) < 0.01 * max(bottoms)

    def is_flag_pattern():
        if len(recent_highs) < 15:
            return False
        flag = recent_highs[-6:]
        return np.std(flag) / np.mean(flag) < 0.01

    def is_pennant_pattern():
        if len(recent_highs) < 15:
            return False
        return is_symmetrical_triangle()

    # íŒ¨í„´ íŒë³„ ìˆœì„œ
    if is_falling_wedge():
        return "í•˜ë½ ìê¸°í˜•"
    elif is_rising_wedge():
        return "ìƒìŠ¹ ìê¸°í˜•"
    elif is_symmetrical_triangle():
        return "ëŒ€ì¹­ ì‚¼ê°í˜•"
    elif is_double_top():
        return "ì´ì¤‘ ì²œì¥"
    elif is_double_bottom():
        return "ì´ì¤‘ ë°”ë‹¥"
    elif is_head_and_shoulders():
        return "í—¤ë“œ ì•¤ ìˆ„ë”"
    elif is_triple_top():
        return "ì‚¼ì¤‘ ì²œì¥"
    elif is_triple_bottom():
        return "ì‚¼ì¤‘ ë°”ë‹¥"
    elif is_flag_pattern():
        return "í”Œë˜ê·¸ íŒ¨í„´"
    elif is_pennant_pattern():
        return "í˜ë„ŒíŠ¸ íŒ¨í„´"
    elif is_ascending_triangle():
        return "ìƒìŠ¹ ì‚¼ê°í˜•"
    elif is_descending_triangle():
        return "í•˜ë½ ì‚¼ê°í˜•"
    elif is_rectangle_range():
        return "ë°•ìŠ¤ê¶Œ"
    elif is_cup_and_handle():
        return "ì»µ ì•¤ í•¸ë“¤"
    else:
        return "none"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3.5) AI ìš”ì•½ ìœ í‹¸ (OpenAI) - í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def validate_inputs(df, rsi, macd, macd_signal, pattern, volume_comment):
    # í•œê¸€ ì£¼ì„: generate_ai_summary í˜¸ì¶œ ì „ í•„ìˆ˜ ê°’/ì»¬ëŸ¼ ê²€ì¦
    if df is None or len(df) < 2:
        raise ValueError("dfê°€ ë¹„ì—ˆê±°ë‚˜ ë°ì´í„°ê°€ 2í–‰ ë¯¸ë§Œì…ë‹ˆë‹¤.")
    required_cols = {"date", "open", "high", "low", "close", "volume"}
    if not required_cols.issubset(set(df.columns)):
        missing = required_cols - set(df.columns)
        raise ValueError(f"dfì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
    for name, val in [("rsi", rsi), ("macd", macd), ("macd_signal", macd_signal), ("pattern", pattern), ("volume_comment", volume_comment)]:
        if val is None or (isinstance(val, float) and pd.isna(val)):
            raise ValueError(f"ì…ë ¥ ê°’ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤: {name}")

def compute_change_metrics(df):
    """
    í•œê¸€ ì£¼ì„: ë³€í™” ì§€í‘œ ê³„ì‚° (ì „ì¼ ëŒ€ë¹„ ìˆ˜ìµë¥ , 7ì¼ í‰ê·  ëŒ€ë¹„ ê´´ë¦¬, ATR(14), ê±°ë˜ëŸ‰ Z-Score)
    dfì—ëŠ” 'date','open','high','low','close','volume'ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •.
    """
    s_close = df["close"].astype(float)
    s_high  = df["high"].astype(float)
    s_low   = df["low"].astype(float)
    s_vol   = df["volume"].astype(float)

    # ì „ì¼ ëŒ€ë¹„ ìˆ˜ìµë¥ (%)
    if len(s_close) >= 2:
        d1_ret = (s_close.iloc[-1] / s_close.iloc[-2] - 1) * 100.0
    else:
        d1_ret = 0.0

    # 7ì¼ í‰ê·  ëŒ€ë¹„ ê´´ë¦¬(%)
    w7 = s_close.tail(7)
    w7_mean = w7.mean() if len(w7) > 0 else s_close.mean()
    dev7 = (s_close.iloc[-1] / w7_mean - 1) * 100.0 if w7_mean else 0.0

    # ATR(14)
    tr_list = []
    for i in range(1, len(df)):
        tr = max(
            s_high.iloc[i] - s_low.iloc[i],
            abs(s_high.iloc[i] - s_close.iloc[i-1]),
            abs(s_low.iloc[i] - s_close.iloc[i-1])
        )
        tr_list.append(tr)
    atr14 = float(pd.Series(tr_list).rolling(14).mean().iloc[-1]) if len(tr_list) >= 14 else float(np.mean(tr_list) if tr_list else 0.0)

    # ê±°ë˜ëŸ‰ Z-Score (ìµœê·¼ 20ì¼)
    vol_tail = s_vol.tail(20) if len(s_vol) >= 20 else s_vol
    mu = float(vol_tail.mean()) if len(vol_tail) else 0.0
    sd = float(vol_tail.std()) if len(vol_tail) else 0.0
    vol_z = (s_vol.iloc[-1] - mu) / (sd + 1e-8) if sd > 0 else 0.0

    return {
        "d1_return_pct": round(float(d1_ret), 2),
        "dev7_pct": round(float(dev7), 2),
        "atr14": round(float(atr14), 4),
        "vol_z": round(float(vol_z), 2),
        "last_close": float(s_close.iloc[-1])
    }

def build_ai_prompt(df, rsi, macd, macd_signal, pattern, volume_comment):
    # í•œê¸€ ì£¼ì„: í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‚¬ì‹¤/í•´ì„ ë¶„ë¦¬, ë³´ìˆ˜ì  í†¤)
    change = compute_change_metrics(df)
    recent = df[["date", "open", "high", "low", "close", "volume"]].tail(7).to_dict("records")
    pattern_text = pattern if pattern and pattern != "none" else "ê°ì§€ë¨ ì—†ìŒ"
    prompt = f"""
ë„ˆëŠ” ë³´ìˆ˜ì ì¸ í¬ë¦½í†  ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼. í•œêµ­ì–´ë¡œ ì‘ì„±í•´.
ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ 'ë³€í™”'ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ë§Œë“¤ì–´.
- ê³¼ì¥/íˆ¬ì ê¶Œìœ /ìˆ˜ìµ ë³´ì¥ ê¸ˆì§€
- 'ì‚¬ì‹¤'ê³¼ 'í•´ì„'ì„ ë¶„ë¦¬

[í•µì‹¬ ì§€í‘œ]
- ì¢…ê°€: {change["last_close"]}
- ì „ì¼ ëŒ€ë¹„ ìˆ˜ìµë¥ (%): {change["d1_return_pct"]}
- 7ì¼ í‰ê·  ëŒ€ë¹„ ê´´ë¦¬(%): {change["dev7_pct"]}
- ATR(14): {change["atr14"]}
- ê±°ë˜ëŸ‰ Z-Score(20ì¼): {change["vol_z"]}
- RSI: {rsi}
- MACD: {macd} / Signal: {macd_signal}
- íŒ¨í„´: {pattern_text}
- ê±°ë˜ëŸ‰ ì½”ë©˜íŠ¸: {volume_comment}

[ìµœê·¼ 7ì¼ ìš”ì•½ ë°ì´í„°] (ìµœì‹ ì´ ë§ˆì§€ë§‰)
{recent}

[ì¶œë ¥ í˜•ì‹]
1) í•œ ì¤„ ìš”ì•½(ì˜¤ëŠ˜ ë¬´ì—‡ì´ ë‹¬ëë‚˜)
2) ì‚¬ì‹¤(Facts): ìˆ«ì/íŒ¨í„´/ë³€í™” í¬ì¸íŠ¸ 3~5ê°œ
3) í•´ì„(Interpretation): ë³´ìˆ˜ì  ê´€ì ì—ì„œ 3~4ë¬¸ì¥
4) ë¦¬ìŠ¤í¬ 2ê°œ (êµ¬ì²´ì  ì§€í‘œ/ì´ë²¤íŠ¸ ê¸°ë°˜)
5) ì‹œë‚˜ë¦¬ì˜¤(ìƒë°©/í•˜ë°©)ì™€ ê°ê°ì˜ íŠ¸ë¦¬ê±° 1ê°œì”©
6) í™•ì‹ ë„(0~100)ì™€ ê·¼ê±° 1ë¬¸ì¥
"""
    return prompt

# ê°„ë‹¨í•œ ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ìœ í‹¸
def _with_retry(fn, max_try=2, base_delay=0.8):
    last = None
    for i in range(max_try):
        last = fn()
        if last:
            return last
        time.sleep(base_delay * (2 ** i))
    return None

def _call_openai_chat(prompt):
    """
    í•œê¸€ ì£¼ì„: OpenAI Chat Completions REST í˜¸ì¶œ (requestsë§Œ ì‚¬ìš©).
    í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”, OPENAI_MODEL ë¯¸ì§€ì • ì‹œ gpt-4o-mini ì‚¬ìš©.
    """
    api_key = os.getenv("OPENAI_API_KEY")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    if not api_key:
        return None
    try:
        url = "https://api.openai.com/v1/chat/completions"
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        body = {
            "model": model,
            "temperature": 0.3,
            "max_tokens": 400,
            "messages": [
                {"role": "system", "content": "You are a cautious Korean crypto analyst. Never give financial advice."},
                {"role": "user", "content": prompt}
            ]
        }
        resp = requests.post(url, headers=headers, json=body, timeout=30)
        resp.raise_for_status()
        j = resp.json()
        return j["choices"][0]["message"]["content"].strip()
    except Exception:
        return None

def generate_ai_summary(df, rsi, macd, macd_signal, pattern, volume_comment):
    """
    í•œê¸€ ì£¼ì„: OpenAI ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ í´ë°± ë¬¸êµ¬ë¡œ ëŒ€ì²´.
    í‚¤ëŠ” ë°˜ë“œì‹œ í™˜ê²½ë³€ìˆ˜(ë˜ëŠ” .env)ë¡œ ì£¼ì….
    """
    validate_inputs(df, rsi, macd, macd_signal, pattern, volume_comment)
    prompt = build_ai_prompt(df, rsi, macd, macd_signal, pattern, volume_comment)

    # 1) OpenAI í˜¸ì¶œ (ìµœëŒ€ 2íšŒ ì¬ì‹œë„)
    text = _with_retry(lambda: _call_openai_chat(prompt), max_try=2, base_delay=0.8)
    provider = 'openai' if text else 'fallback'

    # 2) ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ í´ë°±
    if not text:
        pattern_comment = "ëª…í™•í•œ íŒ¨í„´ ì—†ìŒ" if (not pattern or pattern == "none") else f"'{pattern}' íŒ¨í„´ ê°ì§€"
        text = (
            f"ì‹œì¥ ìš”ì•½: RSI {rsi}, MACD {macd} / ì‹œê·¸ë„ {macd_signal}. {pattern_comment}.\n"
            f"í•´ì„: ê³¼ì¥ ì—†ì´ ë³´ìˆ˜ì ìœ¼ë¡œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. {volume_comment}\n"
            "- ì²´í¬í¬ì¸íŠ¸: ë³€ë™ì„±, ê±°ë˜ëŸ‰ íë¦„\n- ì²´í¬í¬ì¸íŠ¸: ì£¼ìš” ì§€ì§€/ì €í•­ í™•ì¸"
        )

    try:
        print(f"AI provider used: {provider}")
    except Exception:
        pass
    disclaimer = "\n\nâ€» ë³¸ ë‚´ìš©ì€ ì •ë³´ ì œê³µ ëª©ì ì´ë©°, íˆ¬ì ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤."
    return (text + disclaimer).strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ê±°ë˜ëŸ‰ í•´ì„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_volume(df):
    recent_volumes = df["volume"].iloc[-15:-1]  # ì§ì „ 14ì¼
    today_volume   = df["volume"].iloc[-1]
    avg_volume     = recent_volumes.mean()
    if today_volume > avg_volume * 2:
        return f"ê±°ë˜ëŸ‰ì´ í‰ê· ({round(avg_volume,2)}) ëŒ€ë¹„ 2ë°° ì´ìƒ({round(today_volume,2)}) ê¸‰ì¦í•˜ì—¬ ì‹œì¥ ì°¸ì—¬ê°€ í™œë°œí•©ë‹ˆë‹¤."
    elif today_volume > avg_volume * 1.2:
        return f"ê±°ë˜ëŸ‰ì´ í‰ê· ë³´ë‹¤ ë†’ì•„ ë§¤ìˆ˜/ë§¤ë„ ì‹¬ë¦¬ê°€ ê°•í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤."
    else:
        return f"ê±°ë˜ëŸ‰({round(today_volume,2)})ì€ ìµœê·¼ í‰ê· ({round(avg_volume,2)})ê³¼ ìœ ì‚¬í•˜ì—¬ ëšœë ·í•œ ë³€í™”ëŠ” ì—†ìŠµë‹ˆë‹¤."

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) HOT ì½”ì¸ í›„ë³´ ì¶”ì¶œ & ë¬´ì‘ìœ„ 1ê°œ ì„ íƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_krw_markets():
    resp = requests.get("https://api.upbit.com/v1/market/all",
                        params={"isDetails": "false"},
                        headers=UPBIT_HEADERS, timeout=5)
    resp.raise_for_status()
    return [m["market"] for m in resp.json() if m["market"].startswith("KRW-")]

def get_top_movers(top_n=10, min_change=0.05):
    markets = get_krw_markets()
    rows = []
    for i in range(0, len(markets), 100):
        chunk = ",".join(markets[i:i+100])
        r = requests.get("https://api.upbit.com/v1/ticker",
                         params={"markets": chunk},
                         headers=UPBIT_HEADERS, timeout=5)
        r.raise_for_status()
        rows.extend(r.json())
        time.sleep(0.05)  # ì†ë„ ì œí•œ

    df = pd.DataFrame(rows)
    df["change_rate"]  = df["signed_change_rate"].astype(float)
    df["trade_amount"] = df["acc_trade_price_24h"].astype(float)

    cand = (df[df["change_rate"] >= min_change]
            .sort_values(["change_rate", "trade_amount"], ascending=[False, False])
            .head(top_n)["market"].tolist())

    if len(cand) < top_n:
        extra = df.sort_values("trade_amount", ascending=False).head(top_n)["market"].tolist()
        cand = list(dict.fromkeys(cand + extra))[:top_n]
    return cand

def pick_today_hot_coin():
    candidates = get_top_movers()
    print("ğŸ”¥ HOT í›„ë³´:", candidates)
    chosen = random.choice(candidates)
    print("ğŸ¯ ì˜¤ëŠ˜ì˜ HOT ì½”ì¸:", chosen)
    return chosen

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) ë©”ì¸ ì‹¤í–‰: í•« ì½”ì¸ 1ê°œ ë¶„ì„ í›„ Firestore ì €ì¥
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # â‘  ì˜¤ëŠ˜ì˜ í•« ì½”ì¸ ì„ ì •
    hot_market = pick_today_hot_coin()          # ì˜ˆ: 'KRW-ETH'

    # â‘¡ ìº”ë“¤ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = fetch_upbit_daily_candles(hot_market, 30)

    # â‘¢ ì§€í‘œÂ·íŒ¨í„´Â·ê±°ë˜ëŸ‰ ë¶„ì„
    rsi            = calculate_rsi(df["close"])
    macd, macd_sig = calculate_macd(df["close"])
    pattern        = detect_pattern_enhanced(df["high"], df["low"])
    volume_comment = analyze_volume(df)

    # â‘£ RSI ì½”ë©˜íŠ¸
    if rsi < 30:
        rsi_comment = f"RSIê°€ {rsi}ë¡œ ê³¼ë§¤ë„ êµ¬ê°„ì— ì§„ì…í•´ ë°˜ë“± ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
    elif rsi > 70:
        rsi_comment = f"RSIê°€ {rsi}ë¡œ ê³¼ë§¤ìˆ˜ êµ¬ê°„ì— ìœ„ì¹˜í•´ ì¡°ì • ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
    else:
        rsi_comment = f"RSIëŠ” {rsi}ë¡œ ì¤‘ë¦½ êµ¬ê°„ì…ë‹ˆë‹¤."

    # â‘¤ MACD ì½”ë©˜íŠ¸
    if macd > macd_sig:
        macd_comment = f"MACD({macd})ê°€ ì‹œê·¸ë„ì„ ({macd_sig}) ìœ„ë¡œ ëŒíŒŒí•˜ì—¬ ìƒìŠ¹ì„¸ë¡œì˜ ì „í™˜ ì‹ í˜¸ì…ë‹ˆë‹¤."
    else:
        macd_comment = f"MACD({macd})ê°€ ì‹œê·¸ë„ì„ ({macd_sig}) ì•„ë˜ë¡œ ìœ ì§€ë˜ë©° í•˜ë½ì„¸ ì§€ì† ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."

    # â‘¥ íŒ¨í„´ í•´ì„
    pattern_explanations = {
        "í•˜ë½ ìê¸°í˜•": "í†µìƒ í•˜ë½ì„¸ì—ì„œ ë‚˜íƒ€ë‚˜ë©° ì´í›„ ë°˜ë“± ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.",
        "ìƒìŠ¹ ìê¸°í˜•": "ìƒìŠ¹ì„¸ì—ì„œ ë‚˜íƒ€ë‚˜ë©° ì´í›„ ê°€ê²© ì¡°ì • ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.",
        "ëŒ€ì¹­ ì‚¼ê°í˜•": "ë³€ë™ì„± ì¶•ì†Œ í›„ ë°©í–¥ì„± ëŒíŒŒê°€ ì˜ˆìƒë©ë‹ˆë‹¤.",
        "ì´ì¤‘ ì²œì¥": "ê³ ì  ë¶€ê·¼ì—ì„œì˜ í•˜ë½ ë°˜ì „ ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
        "ì´ì¤‘ ë°”ë‹¥": "ì €ì  ë¶€ê·¼ì—ì„œì˜ ìƒìŠ¹ ë°˜ì „ ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
        "í—¤ë“œ ì•¤ ìˆ„ë”": "ìƒìŠ¹ì„¸ ì´í›„ í•˜ë½ ë°˜ì „ì˜ ëŒ€í‘œì ì¸ ì‹ í˜¸ì…ë‹ˆë‹¤.",
        "ì‚¼ì¤‘ ì²œì¥": "ê³ ì ì—ì„œì˜ ê°•í•œ í•˜ë½ ë°˜ì „ ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
        "ì‚¼ì¤‘ ë°”ë‹¥": "ì €ì ì—ì„œì˜ ê°•í•œ ë°˜ë“± ì‹ í˜¸ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "í”Œë˜ê·¸ íŒ¨í„´": "ë‹¨ê¸° ì¡°ì • ì´í›„ ê¸°ì¡´ ì¶”ì„¸ ì§€ì† ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.",
        "í˜ë„ŒíŠ¸ íŒ¨í„´": "ê°€ê²© ì¡°ì • ì´í›„ ì¶”ì„¸ ì§€ì† ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
        "ìƒìŠ¹ ì‚¼ê°í˜•": "ìƒìŠ¹ ëŒíŒŒ ê°€ëŠ¥ì„±ì´ ë†’ì€ íŒ¨í„´ì…ë‹ˆë‹¤.",
        "í•˜ë½ ì‚¼ê°í˜•": "í•˜ë½ ëŒíŒŒ ê°€ëŠ¥ì„±ì´ ë†’ì€ íŒ¨í„´ì…ë‹ˆë‹¤.",
        "ë°•ìŠ¤ê¶Œ": "íš¡ë³´ì¥ì´ ì§€ì†ë  ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
        "ì»µ ì•¤ í•¸ë“¤": "ìƒìŠ¹ ëŒíŒŒ ê°€ëŠ¥ì„±ì„ ê°€ì§€ëŠ” ì¤‘ì¥ê¸° ê°•ì„¸ íŒ¨í„´ì…ë‹ˆë‹¤.",
    }
    if pattern != "none":
        explanation = pattern_explanations.get(pattern, "ê¸°ìˆ ì  í•´ì„ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        pattern_comment = f"í˜„ì¬ '{pattern}' íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. {explanation}"
    else:
        pattern_comment = "í˜„ì¬ ëª…í™•í•œ ì°¨íŠ¸ íŒ¨í„´ì€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # â‘¦ í†µí•© ìš”ì•½
    summary = f"{rsi_comment} {macd_comment} {pattern_comment} {volume_comment}"

    # â‘¦-1) AI ìš”ì•½ (OpenAI â†’ ì‹¤íŒ¨ ì‹œ í´ë°±)
    ai_summary = generate_ai_summary(df, rsi, macd, macd_sig, pattern, volume_comment)

    # â‘§ Firestore ì €ì¥
    symbol = hot_market.replace("KRW-", "")
    today  = datetime.now().strftime("%Y-%m-%d")
    doc_id = f"HOT_{symbol}_{today}"

    data = {
        "symbol": symbol,
        "date": today,
        "rsi": rsi,
        "macd": macd,
        "macdSignal": macd_sig,
        "pattern": pattern,
        "summary": summary,
        "aiSummary": ai_summary,
        "premiumOnly": False,
        "isDailyPick": True,
        "chartData": df.to_dict(orient="records")
    }

    db.collection("daily_analysis").document(doc_id).set(data)
    print(f"âœ… Firestore ì €ì¥ ì™„ë£Œ: {doc_id}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()
